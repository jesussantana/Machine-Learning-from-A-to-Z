{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3613jvsc74a57bd03d9d96423696ce23746d50b417fb1ef1d4900c9a7dc8b757c7d44fb35049bbd2",
   "display_name": "Python 3.6.13 64-bit ('pytorch': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "3d9d96423696ce23746d50b417fb1ef1d4900c9a7dc8b757c7d44fb35049bbd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Multiple Linear Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.preprocessing import StandardScaler\\nsc_X = StandardScaler()\\nX_train = sc_X.fit_transform(X_train)\\nX_test = sc_X.transform(X_test)\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "# Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Import  Dataset\n",
    "\n",
    "dataset = pd.read_csv('../../data/datasets/Part 2 - Regression/Section 5 - Multiple Linear Regression/50_Startups.csv')\n",
    "# Matrix\n",
    "X = dataset.iloc[:, :-1].values\n",
    "# Vector\n",
    "y = dataset.iloc[:, 4].values\n",
    "\n",
    "\n",
    "# Variable scaling\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "## Encode Categorical Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 3] = labelencoder_X.fit_transform(X[:, 3])\n",
    "onehotencoder = make_column_transformer((OneHotEncoder(), [3]), remainder = \"passthrough\")\n",
    "X = onehotencoder.fit_transform(X)"
   ]
  },
  {
   "source": [
    "## Divide the data set into training set and test set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 1.0, 1000.23, 124153.04, 1903.93],\n",
       "       [0.0, 0.0, 1.0, 542.05, 51743.15, 0.0],\n",
       "       [0.0, 0.0, 1.0, 65605.48, 153032.06, 107138.38],\n",
       "       [0.0, 0.0, 1.0, 114523.61, 122616.84, 261776.23],\n",
       "       [0.0, 1.0, 0.0, 61994.48, 115641.28, 91131.24],\n",
       "       [1.0, 0.0, 0.0, 63408.86, 129219.61, 46085.25],\n",
       "       [1.0, 0.0, 0.0, 78013.11, 121597.55, 264346.06],\n",
       "       [1.0, 0.0, 0.0, 23640.93, 96189.63, 148001.11],\n",
       "       [1.0, 0.0, 0.0, 76253.86, 113867.3, 298664.47],\n",
       "       [0.0, 0.0, 1.0, 15505.73, 127382.3, 35534.17],\n",
       "       [0.0, 0.0, 1.0, 120542.52, 148718.95, 311613.29],\n",
       "       [1.0, 0.0, 0.0, 91992.39, 135495.07, 252664.93],\n",
       "       [1.0, 0.0, 0.0, 64664.71, 139553.16, 137962.62],\n",
       "       [0.0, 0.0, 1.0, 131876.9, 99814.71, 362861.36],\n",
       "       [0.0, 0.0, 1.0, 94657.16, 145077.58, 282574.31],\n",
       "       [1.0, 0.0, 0.0, 28754.33, 118546.05, 172795.67],\n",
       "       [1.0, 0.0, 0.0, 0.0, 116983.8, 45173.06],\n",
       "       [1.0, 0.0, 0.0, 162597.7, 151377.59, 443898.53],\n",
       "       [0.0, 1.0, 0.0, 93863.75, 127320.38, 249839.44],\n",
       "       [1.0, 0.0, 0.0, 44069.95, 51283.14, 197029.42],\n",
       "       [0.0, 0.0, 1.0, 77044.01, 99281.34, 140574.81],\n",
       "       [1.0, 0.0, 0.0, 134615.46, 147198.87, 127716.82],\n",
       "       [0.0, 1.0, 0.0, 67532.53, 105751.03, 304768.73],\n",
       "       [0.0, 1.0, 0.0, 28663.76, 127056.21, 201126.82],\n",
       "       [0.0, 0.0, 1.0, 78389.47, 153773.43, 299737.29],\n",
       "       [0.0, 0.0, 1.0, 86419.7, 153514.11, 0.0],\n",
       "       [1.0, 0.0, 0.0, 123334.88, 108679.17, 304981.62],\n",
       "       [1.0, 0.0, 0.0, 38558.51, 82982.09, 174999.3],\n",
       "       [0.0, 1.0, 0.0, 1315.46, 115816.21, 297114.46],\n",
       "       [0.0, 0.0, 1.0, 144372.41, 118671.85, 383199.62],\n",
       "       [0.0, 0.0, 1.0, 165349.2, 136897.8, 471784.1],\n",
       "       [1.0, 0.0, 0.0, 0.0, 135426.92, 0.0],\n",
       "       [1.0, 0.0, 0.0, 22177.74, 154806.14, 28334.72]], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "source": [
    "## Fit the Multiple Linear Regression model with the training set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regression = LinearRegression()\n",
    "regression.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "## Prediction of the results in the test set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[111616.64259458 132709.39466316 140155.11033799  76099.20398185\n 186329.94240377 112822.1980725   63002.00394799  99107.10428093\n 119287.75473384 175522.83864744 101000.69861503  85772.99293232\n 117713.76481532  90230.88085198 133375.04389455 167530.54765834\n 158013.5460207 ]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "source": [
    "## Build the optimal RLM model using Backward Elimination"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "X = np.append(arr = np.ones((50,1)).astype(int), values = X, axis = 1)\n",
    "SL = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.001\n",
       "Model:                            OLS   Adj. R-squared:                 -0.020\n",
       "Method:                 Least Squares   F-statistic:                   0.04727\n",
       "Date:                Thu, 06 May 2021   Prob (F-statistic):              0.829\n",
       "Time:                        16:20:26   Log-Likelihood:                -600.63\n",
       "No. Observations:                  50   AIC:                             1205.\n",
       "Df Residuals:                      48   BIC:                             1209.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       1.111e+05   7085.628     15.682      0.000    9.69e+04    1.25e+05\n",
       "x1          2642.1322   1.22e+04      0.217      0.829   -2.18e+04    2.71e+04\n",
       "==============================================================================\n",
       "Omnibus:                        0.011   Durbin-Watson:                   0.021\n",
       "Prob(Omnibus):                  0.994   Jarque-Bera (JB):                0.082\n",
       "Skew:                           0.022   Prob(JB):                        0.960\n",
       "Kurtosis:                       2.807   Cond. No.                         2.41\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ],
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.001</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.020</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td> 0.04727</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Thu, 06 May 2021</td> <th>  Prob (F-statistic):</th>  <td> 0.829</td> \n</tr>\n<tr>\n  <th>Time:</th>                 <td>16:20:26</td>     <th>  Log-Likelihood:    </th> <td> -600.63</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1205.</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1209.</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th> <td> 1.111e+05</td> <td> 7085.628</td> <td>   15.682</td> <td> 0.000</td> <td> 9.69e+04</td> <td> 1.25e+05</td>\n</tr>\n<tr>\n  <th>x1</th>    <td> 2642.1322</td> <td> 1.22e+04</td> <td>    0.217</td> <td> 0.829</td> <td>-2.18e+04</td> <td> 2.71e+04</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td> 0.011</td> <th>  Durbin-Watson:     </th> <td>   0.021</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.994</td> <th>  Jarque-Bera (JB):  </th> <td>   0.082</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td> 0.022</td> <th>  Prob(JB):          </th> <td>   0.960</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 2.807</td> <th>  Cond. No.          </th> <td>    2.41</td>\n</tr>\n</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "X_opt = X[:, [0, 1, 2, 3, 4, 5]]\n",
    "regression_OLS = sm.OLS(endog = y, exog = X_opt.tolist()).fit()\n",
    "regression_OLS.summary()\n",
    "\n",
    "X_opt = X[:, [0, 1, 3, 4, 5]]\n",
    "regression_OLS = sm.OLS(endog = y, exog = X_opt.tolist()).fit()\n",
    "regression_OLS.summary()\n",
    "\n",
    "X_opt = X[:, [0, 3, 4, 5]]\n",
    "regression_OLS = sm.OLS(endog = y, exog = X_opt.tolist()).fit()\n",
    "regression_OLS.summary()\n",
    "\n",
    "X_opt = X[:, [0, 3, 5]]\n",
    "regression_OLS = sm.OLS(endog = y, exog = X_opt.tolist()).fit()\n",
    "regression_OLS.summary()\n",
    "\n",
    "X_opt = X[:, [0, 3]]\n",
    "regression_OLS = sm.OLS(endog = y, exog = X_opt.tolist()).fit()\n",
    "regression_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "def backwardElimination(x, sl):    \n",
    "    numVars = len(x[0])    \n",
    "    for i in range(0, numVars):        \n",
    "        regressor_OLS = sm.OLS(y, x.tolist()).fit()        \n",
    "        maxVar = max(regressor_OLS.pvalues).astype(float)        \n",
    "        if maxVar > sl:            \n",
    "            for j in range(0, numVars - i):                \n",
    "                if (regressor_OLS.pvalues[j].astype(float) == maxVar):                    \n",
    "                    x = np.delete(x, j, 1)    \n",
    "    regressor_OLS.summary()    \n",
    "    return x \n",
    " \n",
    "SL = 0.05\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5, 6]]\n",
    "X_Modeled = backwardElimination(X_opt, SL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}